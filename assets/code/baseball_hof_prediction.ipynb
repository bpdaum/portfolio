{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting Hall of Fame Inductees (Data Science Portfolio)\n",
                "\n",
                "## Objective\n",
                "Build an XGBoost classifier to predict Baseball Hall of Fame induction using locally stored Lahman Database CSV files, followed by a deeper interpretation using **SHAP** values.\n",
                "\n",
                "## Data Source\n",
                "We use three CSV files located in `../../data/baseball/`:\n",
                "1.  **Batting.csv**: Career batting statistics.\n",
                "2.  **HallOfFame.csv**: Ground truth labels for induction.\n",
                "3.  **People.csv**: Player names and biographical details.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (if needed)\n",
                "!pip install pandas numpy xgboost scikit-learn matplotlib seaborn shap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import shap\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "\n",
                "plt.style.use('fivethirtyeight')\n",
                "# Initialize JS for SHAP plots\n",
                "shap.initjs()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "Load the CSVs into Pandas DataFrames. We assume the notebook is running in `assets/code/` and data is in `data/baseball/` (2 levels up)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths (Update this to './' if running in Colab with direct upload)\n",
                "DATA_DIR = '../../data/baseball/'\n",
                "\n",
                "try:\n",
                "    df_batting = pd.read_csv(os.path.join(DATA_DIR, 'Batting.csv'))\n",
                "    df_hof = pd.read_csv(os.path.join(DATA_DIR, 'HallOfFame.csv'))\n",
                "    df_people = pd.read_csv(os.path.join(DATA_DIR, 'People.csv'))\n",
                "    \n",
                "    print(\"Data Loaded Successfully!\")\n",
                "    print(f\"Batting: {df_batting.shape}\")\n",
                "    print(f\"HOF: {df_hof.shape}\")\n",
                "    print(f\"People: {df_people.shape}\")\n",
                "    \n",
                "except FileNotFoundError:\n",
                "    print(\"Error: CSV files not found. Please check the DATA_DIR path.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing & Aggregation\n",
                "We need to transform season-level batting stats into **Player Career Totals**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Aggregate Batting Stats by PlayerID\n",
                "cols_to_sum = ['G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'BB', 'SO']\n",
                "\n",
                "# Ensure columns are numeric\n",
                "for col in cols_to_sum:\n",
                "    df_batting[col] = pd.to_numeric(df_batting[col], errors='coerce').fillna(0)\n",
                "\n",
                "career_stats = df_batting.groupby('playerID')[cols_to_sum].sum().reset_index()\n",
                "\n",
                "# 2. Calculate Career Batting Average\n",
                "# Avoid division by zero\n",
                "career_stats['AVG'] = np.where(career_stats['AB'] > 0, career_stats['H'] / career_stats['AB'], 0)\n",
                "\n",
                "# 3. Merge with People to get Names\n",
                "career_stats = career_stats.merge(df_people[['playerID', 'nameFirst', 'nameLast']], on='playerID', how='left')\n",
                "career_stats['Name'] = career_stats['nameFirst'] + ' ' + career_stats['nameLast']\n",
                "\n",
                "# Filter for significant careers (> 2000 ABs)\n",
                "career_stats = career_stats[career_stats['AB'] > 2000]\n",
                "\n",
                "print(f\"Filtered Career Players: {len(career_stats)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Labeling (HOF Status)\n",
                "Identify players who were inducted into the Hall of Fame using the `HallOfFame` table."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get list of inducted IDs (inducted = 'Y')\n",
                "hof_inductees = df_hof[df_hof['inducted'] == 'Y']['playerID'].unique()\n",
                "\n",
                "# Create Target Column\n",
                "career_stats['is_hof'] = career_stats['playerID'].isin(hof_inductees).astype(int)\n",
                "\n",
                "print(f\"Total Inductees in Dataset: {career_stats['is_hof'].sum()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Training (XGBoost)\n",
                "Train the model using the aggregated stats."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features = ['G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'BB', 'SO', 'AVG']\n",
                "X = career_stats[features]\n",
                "y = career_stats['is_hof']\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Train XGBoost\n",
                "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Model Trained Successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
                "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
                "\n",
                "# Confusion Matrix\n",
                "plt.figure(figsize=(6, 4))\n",
                "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
                "plt.title('Confusion Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Misses & Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "test_df = X_test.copy()\n",
                "test_df['Name'] = career_stats.loc[test_df.index, 'Name']\n",
                "test_df['Actual'] = y_test\n",
                "test_df['Predicted'] = y_pred\n",
                "\n",
                "# Snubs (False Negatives)\n",
                "snubs = test_df[(test_df['Actual'] == 1) & (test_df['Predicted'] == 0)]\n",
                "print(\"Model 'Snubs' (Actual HOFers predicted as NO):\")\n",
                "display(snubs[['Name', 'H', 'HR', 'AVG']].head(5))\n",
                "\n",
                "# Controversial (False Positives)\n",
                "candidates = test_df[(test_df['Actual'] == 0) & (test_df['Predicted'] == 1)]\n",
                "print(\"\\nModel Candidates (Not HOF but predicted YES):\")\n",
                "display(candidates[['Name', 'H', 'HR', 'AVG']].head(5))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Interpretation with SHAP\n",
                "While XGBoost gives us \"Feature Importance\", **SHAP (SHapley Additive exPlanations)** tells us *how* each feature affects the prediction. \n",
                "\n",
                "*   **Red dots** = High value of the feature (e.g., lots of Hits).\n",
                "*   **Right side** = Higher chance of being HOF."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the explainer\n",
                "explainer = shap.TreeExplainer(model)\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "# 1. Summary Plot (The single most useful view)\n",
                "plt.title(\"Feature Impact on HOF Probability\")\n",
                "shap.summary_plot(shap_values, X_test, plot_type=\"dot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Explaining Single Predictions\n",
                "Let's zoom in on one of our \"False Positives\" (a player predicted to be in the HOF who isn't). Why did the model think they should be inducted?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if not candidates.empty:\n",
                "    # Pick the first 'False Positive' from our list\n",
                "    player_idx = candidates.index[0]\n",
                "    player_name = candidates.loc[player_idx, 'Name']\n",
                "    \n",
                "    print(f\"Explaining prediction for: {player_name}\")\n",
                "    \n",
                "    # Get the location in X_test (integer index)\n",
                "    # Note: candidates.index contains original DF indices. We need the positional index in X_test.\n",
                "    pos_idx = X_test.index.get_loc(player_idx)\n",
                "    \n",
                "    # Waterfall plot shows how each stat pushed the probability up or down from the baseline\n",
                "    shap.plots.waterfall(shap.Explanation(values=shap_values[pos_idx], \n",
                "                                          base_values=explainer.expected_value, \n",
                "                                          data=X_test.iloc[pos_idx], \n",
                "                                          feature_names=X_test.columns))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}