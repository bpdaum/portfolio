{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Predicting Hall of Fame Inductees (Data Science Portfolio)\n",
                "\n",
                "## Objective\n",
                "Build an XGBoost classifier to predict Baseball Hall of Fame induction using locally stored Lahman Database CSV files. \n",
                "\n",
                "**Key enhancements:**\n",
                "*   **Feature Engineering**: OPS, ISO, Era/Decade adjustments.\n",
                "*   **Bias Correction**: Filtering out active/recent players from training to avoid recency bias.\n",
                "*   **Advanced Evaluation**: Using ROC-AUC and F1-Score for imbalanced class assessment.\n",
                "*   **Interpretability**: SHAP analysis.\n",
                "\n",
                "## Data Source\n",
                "We use three CSV files located in `../../data/baseball/`:\n",
                "1.  **Batting.csv**: Career batting statistics.\n",
                "2.  **HallOfFame.csv**: Ground truth labels for induction.\n",
                "3.  **People.csv**: Player names and biographical details.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install dependencies (if needed)\n",
                "!pip install pandas numpy xgboost scikit-learn matplotlib seaborn shap"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import shap\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score, recall_score, precision_score\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import os\n",
                "\n",
                "plt.style.use('fivethirtyeight')\n",
                "# Initialize JS for SHAP plots\n",
                "shap.initjs()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading\n",
                "Load the CSVs into Pandas DataFrames. We assume the notebook is running in `assets/code/` and data is in `data/baseball/` (2 levels up)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths (Update this to './' if running in Colab with direct upload)\n",
                "DATA_DIR = '../../data/baseball/'\n",
                "\n",
                "try:\n",
                "    df_batting = pd.read_csv(os.path.join(DATA_DIR, 'Batting.csv'))\n",
                "    df_hof = pd.read_csv(os.path.join(DATA_DIR, 'HallOfFame.csv'))\n",
                "    df_people = pd.read_csv(os.path.join(DATA_DIR, 'People.csv'))\n",
                "    \n",
                "    print(\"Data Loaded Successfully!\")\n",
                "    print(f\"Batting: {df_batting.shape}\")\n",
                "    print(f\"HOF: {df_hof.shape}\")\n",
                "    print(f\"People: {df_people.shape}\")\n",
                "    \n",
                "except FileNotFoundError:\n",
                "    print(\"Error: CSV files not found. Please check the DATA_DIR path.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing & Feature Engineering\n",
                "We transform season-level stats into career totals, and then derive advanced sabermetric indicators."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Aggregate Batting Stats by PlayerID\n",
                "# Added HBP (Hit by Pitch) and SF (Sacrifice Fly) for accurate OBP calculation\n",
                "cols_to_sum = ['G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'BB', 'SO', 'HBP', 'SF']\n",
                "\n",
                "# Ensure columns are numeric\n",
                "for col in cols_to_sum:\n",
                "    if col in df_batting.columns:\n",
                "        df_batting[col] = pd.to_numeric(df_batting[col], errors='coerce').fillna(0)\n",
                "\n",
                "# We also need yearID to calculate Career Span and Decade\n",
                "career_stats = df_batting.groupby('playerID').agg(\n",
                "    {**{col: 'sum' for col in cols_to_sum}, \n",
                "     'yearID': ['min', 'max']}  # Get First and Last Year\n",
                ").reset_index()\n",
                "\n",
                "# Fix Column Names after Aggregation (Flatten MultiIndex)\n",
                "new_cols = []\n",
                "for col in career_stats.columns.values:\n",
                "    if col[1] == 'sum':\n",
                "        new_cols.append(col[0]) # Keep original name for sums (e.g. 'AB' not 'AB_sum')\n",
                "    elif col[1]:\n",
                "        new_cols.append(f\"{col[0]}_{col[1]}\") # Keep suffix for others (e.g. 'yearID_min')\n",
                "    else:\n",
                "        new_cols.append(col[0]) # Keep index name 'playerID'\n",
                "        \n",
                "career_stats.columns = new_cols\n",
                "\n",
                "# Rename year columns for clarity\n",
                "career_stats.rename(columns={'yearID_min': 'FirstYear', 'yearID_max': 'LastYear'}, inplace=True)\n",
                "\n",
                "# 2. Calculate Basic Rates\n",
                "career_stats['AVG'] = np.where(career_stats['AB'] > 0, career_stats['H'] / career_stats['AB'], 0)\n",
                "\n",
                "# 3. ADVANCED FEATURE ENGINEERING\n",
                "\n",
                "# -- ERA / DECADE FEATURES --\n",
                "career_stats['YearsPlayed'] = career_stats['LastYear'] - career_stats['FirstYear'] + 1\n",
                "# Calculate 'Primary Decade' (midpoint of career rounded to nearest 10)\n",
                "career_stats['Decade'] = (((career_stats['FirstYear'] + career_stats['LastYear']) / 2) // 10 * 10).astype(int)\n",
                "\n",
                "# -- SABERMETRICS --\n",
                "# Plate Appearances (PA)\n",
                "career_stats['PA'] = career_stats['AB'] + career_stats['BB'] + career_stats['HBP'] + career_stats['SF']\n",
                "\n",
                "# On-Base Percentage (OBP)\n",
                "career_stats['OBP'] = np.where(career_stats['PA'] > 0, \n",
                "                               (career_stats['H'] + career_stats['BB'] + career_stats['HBP']) / career_stats['PA'], 0)\n",
                "\n",
                "# Slugging Percentage (SLG)\n",
                "# TB = H + 2B + 2*3B + 3*HR\n",
                "total_bases = career_stats['H'] + career_stats['2B'] + (2 * career_stats['3B']) + (3 * career_stats['HR'])\n",
                "career_stats['SLG'] = np.where(career_stats['AB'] > 0, total_bases / career_stats['AB'], 0)\n",
                "\n",
                "# On-Base Plus Slugging (OPS)\n",
                "career_stats['OPS'] = career_stats['OBP'] + career_stats['SLG']\n",
                "\n",
                "# Isolated Power (ISO)\n",
                "career_stats['ISO'] = career_stats['SLG'] - career_stats['AVG']\n",
                "\n",
                "# Walk Rate and Strikeout Rate\n",
                "career_stats['BB_Rate'] = np.where(career_stats['PA'] > 0, career_stats['BB'] / career_stats['PA'], 0)\n",
                "career_stats['K_Rate']  = np.where(career_stats['PA'] > 0, career_stats['SO'] / career_stats['PA'], 0)\n",
                "\n",
                "# 4. Merge with People to get Names\n",
                "career_stats = career_stats.merge(df_people[['playerID', 'nameFirst', 'nameLast']], on='playerID', how='left')\n",
                "career_stats['Name'] = career_stats['nameFirst'] + ' ' + career_stats['nameLast']\n",
                "\n",
                "# Filter for significant careers (> 2000 ABs)\n",
                "career_stats = career_stats[career_stats['AB'] > 2000]\n",
                "\n",
                "print(f\"All Players (Significant Careers): {len(career_stats)}\")\n",
                "career_stats[['Name', 'Decade', 'YearsPlayed', 'OPS']].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Labeling & Splitting\n",
                "**CRITICAL STEP**: We must separate players who have completed their careers from those who are still active or recently retired.\n",
                "*   **Training Data**: Players who retired before 2019 (Eligible for HOF).\n",
                "*   **Prediction Data**: Players who played in 2019 or later (Future candidates)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get list of inducted IDs (inducted = 'Y')\n",
                "hof_inductees = df_hof[df_hof['inducted'] == 'Y']['playerID'].unique()\n",
                "\n",
                "# Create Target Column\n",
                "career_stats['is_hof'] = career_stats['playerID'].isin(hof_inductees).astype(int)\n",
                "\n",
                "# --- FILTERING STEP ---\n",
                "ELIGIBILITY_CUTOFF = 2019\n",
                "\n",
                "df_eligible = career_stats[career_stats['LastYear'] < ELIGIBILITY_CUTOFF].copy()\n",
                "df_future = career_stats[career_stats['LastYear'] >= ELIGIBILITY_CUTOFF].copy()\n",
                "\n",
                "print(f\"Training Set (retired before {ELIGIBILITY_CUTOFF}): {len(df_eligible)} players\")\n",
                "print(f\"Future Prediction Set (active/recent): {len(df_future)} players\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Exploratory Data Analysis (EDA)\n",
                "Visualizing the statistical profile of Hall of Famers (using only the eligible training data)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Correlation Heatmap\n",
                "plt.figure(figsize=(12, 10))\n",
                "features_to_plot = ['H', 'HR', 'RBI', 'AVG', 'OBP', 'SLG', 'OPS', 'Decade', 'is_hof']\n",
                "sns.heatmap(df_eligible[features_to_plot].corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
                "plt.title('Correlation (Eligible Players Only)')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Scatter Plot: OPS vs. Hits\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(data=df_eligible, x='H', y='OPS', hue='is_hof', alpha=0.6, palette={0: 'gray', 1: 'gold'})\n",
                "plt.title('Career Hits vs. OPS (Gold = HOF)')\n",
                "plt.axvline(x=3000, color='red', linestyle='--', linewidth=1, label='3000 Hits')\n",
                "plt.axhline(y=0.900, color='blue', linestyle='--', linewidth=1, label='0.900 OPS')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Box Plots: Statistical Distribution\n",
                "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
                "\n",
                "sns.boxplot(x='is_hof', y='OPS', data=df_eligible, ax=axes[0], palette='Set2')\n",
                "axes[0].set_title('Distribution of Career OPS')\n",
                "\n",
                "sns.boxplot(x='is_hof', y='YearsPlayed', data=df_eligible, ax=axes[1], palette='Set2')\n",
                "axes[1].set_title('Distribution of Years Played')\n",
                "\n",
                "sns.boxplot(x='is_hof', y='Decade', data=df_eligible, ax=axes[2], palette='Set2')\n",
                "axes[2].set_title('Distribution of Decade Played')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Model Training (XGBoost)\n",
                "Train using only the `df_eligible` dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "features = [\n",
                "    'G', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB', 'BB', 'SO', \n",
                "    'AVG', 'OBP', 'SLG', 'OPS', 'ISO', 'BB_Rate', 'K_Rate',\n",
                "    'YearsPlayed', 'Decade'\n",
                "]\n",
                "X = df_eligible[features]\n",
                "y = df_eligible['is_hof']\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Train XGBoost\n",
                "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=200, random_state=42)\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "print(\"Model Trained Successfully on Eligible Players.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Evaluation\n",
                "Given the imbalanced nature of HOF induction (very few players get in), **Accuracy** is not enough. \n",
                "We use **F1-Score**, **ROC-AUC**, and **Recall** (Sensitivity) to measure how well we identify the rare HOF talent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "y_pred = model.predict(X_test)\n",
                "y_prob = model.predict_proba(X_test)[:, 1]\n",
                "\n",
                "# Calculate Metrics\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "precision = precision_score(y_test, y_pred)\n",
                "recall = recall_score(y_test, y_pred)\n",
                "f1 = f1_score(y_test, y_pred)\n",
                "roc_auc = roc_auc_score(y_test, y_prob)\n",
                "\n",
                "print(f\"Accuracy:  {accuracy:.4f}\")\n",
                "print(f\"Precision: {precision:.4f}\")\n",
                "print(f\"Recall:    {recall:.4f} (Correctly identified HOFers)\")\n",
                "print(f\"F1 Score:  {f1:.4f}\")\n",
                "print(f\"ROC-AUC:   {roc_auc:.4f}\")\n",
                "\n",
                "# Visualization\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# 1. Confusion Matrix (Normalized)\n",
                "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
                "sns.heatmap(cm, annot=True, fmt='.2%', cmap='Blues', ax=axes[0])\n",
                "axes[0].set_title('Normalized Confusion Matrix')\n",
                "axes[0].set_xlabel('Predicted')\n",
                "axes[0].set_ylabel('Actual')\n",
                "axes[0].set_xticklabels(['Not HOF', 'HOF'])\n",
                "axes[0].set_yticklabels(['Not HOF', 'HOF'])\n",
                "\n",
                "# 2. ROC Curve\n",
                "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
                "axes[1].plot(fpr, tpr, label=f'AUC = {roc_auc:.2f}')\n",
                "axes[1].plot([0, 1], [0, 1], 'r--')\n",
                "axes[1].set_title('ROC Curve')\n",
                "axes[1].set_xlabel('False Positive Rate')\n",
                "axes[1].set_ylabel('True Positive Rate')\n",
                "axes[1].legend(loc='lower right')\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Model Interpretation with SHAP\n",
                "Do we still see a Decade bias now that we've removed recent players?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create the explainer\n",
                "explainer = shap.TreeExplainer(model)\n",
                "shap_values = explainer.shap_values(X_test)\n",
                "\n",
                "# 1. Summary Plot\n",
                "plt.title(\"Feature Impact on HOF Probability\")\n",
                "shap.summary_plot(shap_values, X_test, plot_type=\"dot\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8. PREDICTING THE FUTURE\n",
                "Now for the fun part! We apply our trained model to the `df_future` dataset (Active/Recent players) to see who has the best shot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_future = df_future[features]\n",
                "\n",
                "# Predict Probabilities\n",
                "future_probs = model.predict_proba(X_future)[:, 1]\n",
                "\n",
                "df_future['HOF_Probability'] = future_probs\n",
                "\n",
                "# Display Top 15 Candidates\n",
                "top_candidates = df_future.sort_values(by='HOF_Probability', ascending=False).head(20)\n",
                "\n",
                "display(top_candidates[['Name', 'HOF_Probability', 'H', 'HR', 'OPS', 'YearsPlayed', 'Decade']])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Case Study: Defensive Specialists (Hedges & Mathis)\n",
                "The user requested an analysis of **Austin Hedges** and **Jeff Mathis**. Both are famous for being elite defensive catchers with historically low batting metrics.\n",
                "\n",
                "Let's see if the model (which only sees batting stats) gives them *any* chance, and use SHAP to explain why."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "target_players = ['Austin Hedges', 'Jeff Mathis']\n",
                "\n",
                "for player_name in target_players:\n",
                "    # Find the player in the FUTURE dataset (since they are recent/active)\n",
                "    player_row = df_future[df_future['Name'] == player_name]\n",
                "    \n",
                "    if not player_row.empty:\n",
                "        # Get the index relative to X_future\n",
                "        # Loop in case there are duplicates (unlikely for these 2 but good practice)\n",
                "        for idx in player_row.index:\n",
                "            # We need to compute SHAP values for the FUTURE set first\n",
                "            # (We only computed X_test earlier)\n",
                "            shap_values_future = explainer.shap_values(X_future)\n",
                "            \n",
                "            # Find positional index in X_future\n",
                "            pos_idx = X_future.index.get_loc(idx)\n",
                "\n",
                "            print(f\"\\nSHAP Analysis for {player_name}:\")\n",
                "            print(f\"HOF Probability: {player_row.loc[idx, 'HOF_Probability']:.4f}\")\n",
                "            \n",
                "            shap.plots.waterfall(shap.Explanation(values=shap_values_future[pos_idx], \n",
                "                                                  base_values=explainer.expected_value, \n",
                "                                                  data=X_future.iloc[pos_idx], \n",
                "                                                  feature_names=features))\n",
                "    else:\n",
                "        print(f\"Player {player_name} not found in the filtered dataset (Check spelling or AB threshold).\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}